{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2a4e24d-8b4f-4cf9-9057-7f764a1712e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word Embedding for 'nlp':\n",
      " [-0.01630604  0.00899287 -0.00826389  0.00163419  0.0169904 ]\n",
      "\n",
      "Similarity(nlp, language): -0.31977788\n",
      "Similarity(nlp, class): -0.119261764\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Alternate Word Embedding using Gensim\n",
    "# -------------------------------\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "corpus = [\n",
    "    \"I am loving the NLP class, but sometimes it feels confusing!\",\n",
    "    \"NLP is a fascinating field — it deals with text, speech, and language understanding.\"\n",
    "]\n",
    "\n",
    "# Step 1: Tokenize corpus\n",
    "tokens = [word_tokenize(sent.lower()) for sent in corpus]\n",
    "\n",
    "# Step 2: Train Word2Vec model (min_count=1 ensures all words are used)\n",
    "model = Word2Vec(tokens, vector_size=50, window=3, min_count=1, sg=1)\n",
    "\n",
    "# Step 3: Display word vectors\n",
    "print(\"\\nWord Embedding for 'nlp':\\n\", model.wv['nlp'][:5])  # first 5 numbers\n",
    "\n",
    "# Step 4: Check similarity between words\n",
    "print(\"\\nSimilarity(nlp, language):\", model.wv.similarity('nlp', 'language'))\n",
    "print(\"Similarity(nlp, class):\", model.wv.similarity('nlp', 'class'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "560e1c5d-1211-45ee-afa8-e5eccd651b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocabulary in Model:\n",
      "[',', 'nlp', 'it', '.', 'understanding', 'am', 'loving', 'the', 'class', 'but', 'sometimes', 'feels', 'confusing', '!', 'is', 'a', 'fascinating', 'field', '—', 'deals', 'with', 'text', 'speech', 'and', 'language', 'i']\n",
      "\n",
      "Vector for word 'nlp':\n",
      "[-0.01630604  0.00899287 -0.00826389  0.00163419  0.0169904  -0.00893342\n",
      "  0.00902868 -0.0135695  -0.00710388  0.01878386 -0.00314644  0.00063232\n",
      " -0.00826854 -0.015368   -0.00301742  0.00493723 -0.00176314  0.0110779\n",
      " -0.00549505  0.00451258  0.0109021   0.01669286 -0.00289699 -0.01841494\n",
      "  0.00873734  0.00114928  0.01488332 -0.00162273 -0.00527408 -0.01750709\n",
      " -0.00172094  0.00564497  0.0108108   0.0141087  -0.01141115  0.00371566\n",
      "  0.01218499 -0.00960279 -0.00622708  0.01358758  0.00325974  0.00037814\n",
      "  0.00694768  0.00043663  0.01923922  0.01011519 -0.01783127 -0.01408236\n",
      "  0.00179584  0.0127875 ]\n",
      "\n",
      "Most similar words to 'nlp':\n",
      "[('fascinating', 0.22991271317005157), ('i', 0.21886946260929108), ('deals', 0.16039878129959106), ('—', 0.14868152141571045), ('understanding', 0.1248973160982132), ('confusing', 0.08053866028785706), ('loving', 0.0741451233625412), ('text', 0.05517461895942688), (',', 0.04255583882331848), ('am', 0.01831701025366783)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------\n",
    "# Q.4: Word2Vec Implementation in Python\n",
    "# --------------------------------------\n",
    "\n",
    "# Step 1: Import libraries\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Step 2: Define the corpus (same two sentences)\n",
    "doc1 = \"I am loving the NLP class, but sometimes it feels confusing!\"\n",
    "doc2 = \"NLP is a fascinating field — it deals with text, speech, and language understanding.\"\n",
    "\n",
    "# Step 3: Tokenize each document (convert text → list of words)\n",
    "tokens_doc1 = word_tokenize(doc1.lower())\n",
    "tokens_doc2 = word_tokenize(doc2.lower())\n",
    "\n",
    "# Step 4: Combine all tokenized documents into a single list for training\n",
    "corpus = [tokens_doc1, tokens_doc2]\n",
    "\n",
    "# Step 5: Train the Word2Vec model\n",
    "model = Word2Vec(sentences=corpus, vector_size=50, window=3, min_count=1, sg=1)\n",
    "# vector_size = dimensionality of word vectors\n",
    "# window = number of context words to consider\n",
    "# min_count = ignore words with frequency < 1\n",
    "# sg = 1 means use Skip-gram (0 would mean CBOW)\n",
    "\n",
    "# Step 6: Display vocabulary words\n",
    "print(\"\\nVocabulary in Model:\")\n",
    "print(list(model.wv.index_to_key))\n",
    "\n",
    "# Step 7: Display vector representation of a word\n",
    "print(\"\\nVector for word 'nlp':\")\n",
    "print(model.wv['nlp'])\n",
    "\n",
    "# Step 8: Find most similar words to a given word\n",
    "print(\"\\nMost similar words to 'nlp':\")\n",
    "print(model.wv.most_similar('nlp'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd23742-0f2d-451c-a0a0-037bd9846bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp_env]",
   "language": "python",
   "name": "conda-env-nlp_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
